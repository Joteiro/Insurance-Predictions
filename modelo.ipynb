{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de crear el modelo, es necesario preparar los datos, incluyendo la fusión de ambos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datasets\n",
    "insurance_data = pd.read_csv('insurance_data.csv')\n",
    "vehicle_info = pd.read_csv('vehicle_info.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juant\\AppData\\Local\\Temp\\ipykernel_14132\\2092013742.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[column] = le.fit_transform(features[column])\n",
      "C:\\Users\\juant\\AppData\\Local\\Temp\\ipykernel_14132\\2092013742.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[column] = le.fit_transform(features[column])\n",
      "C:\\Users\\juant\\AppData\\Local\\Temp\\ipykernel_14132\\2092013742.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[column] = le.fit_transform(features[column])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Fusionar datasets\n",
    "merged_data = pd.merge(insurance_data, vehicle_info, on='VEHICLE_ID')\n",
    "\n",
    "# One-Hot Encoding para la variable categórica \"TYPE_VEHICLE\"\n",
    "merged_data = pd.get_dummies(merged_data, columns=['TYPE_VEHICLE'], drop_first=True)\n",
    "\n",
    "# Seleccionar características relevantes\n",
    "features = merged_data[['CUSTOMER_SENIORITY', 'SEX', 'INSR_TYPE', 'INSURED_VALUE', 'PREMIUM', 'USAGE', 'PROD_YEAR', 'SEATS_NUM', 'CARRYING_CAPACITY', 'CCM_TON'] + [col for col in merged_data.columns if 'TYPE_VEHICLE_' in col]]\n",
    "target = merged_data['CLAIM_PAID'].notnull().astype(int)  # 1 si hay reclamo, 0 si no\n",
    "\n",
    "# Codificar variables categóricas\n",
    "label_encoders = {}\n",
    "for column in ['SEX', 'INSR_TYPE', 'USAGE']:\n",
    "    le = LabelEncoder()\n",
    "    features[column] = le.fit_transform(features[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Imputar valores faltantes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features = pd.DataFrame(imputer.fit_transform(features), columns=features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos en conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divide el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asignación de resultados\n",
    "\n",
    "- X_train y y_train: Contendrán los datos de características y objetivos, respectivamente, que se usarán para entrenar el modelo.\n",
    "- X_test y y_test: Contendrán los datos de características y objetivos, respectivamente, que se usarán para evaluar el rendimiento del modelo después del entrenamiento.\n",
    "\n",
    "#### Parámetros de train_test_split\n",
    "\n",
    "- features: Conjunto de datos que contiene las características o variables independientes que se usarán para entrenar el modelo.\n",
    "- target: Conjunto de datos que contiene la variable objetivo o dependiente que el modelo intentará predecir.\n",
    "- test_size=0.2: Especifica la proporción del conjunto de datos que se debe usar como conjunto de prueba. En este caso, el 20% de los datos se utilizarán para la prueba y el 80% restante para el entrenamiento.\n",
    "- random_state=42: Establece una semilla para el generador de números aleatorios, lo que garantiza que la división de los datos sea reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posibilidades:\n",
    "\n",
    "1) Regresión Logística: Simple y fácil de interpretar, útil para clasificación binaria.\n",
    "2) Random Forest (conjunto  de Árboles de Decisión): Capturan relaciones no lineales y son robustos a datos ruidosos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     74631\n",
      "           1       0.28      0.01      0.02      6659\n",
      "\n",
      "    accuracy                           0.92     81290\n",
      "   macro avg       0.60      0.50      0.49     81290\n",
      "weighted avg       0.87      0.92      0.88     81290\n",
      "\n",
      "ROC AUC Score: 0.7259874662832552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Regresión Logística\")\n",
    "print(classification_report(y_test, y_pred_logistic))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, logistic_model.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase 0 representa pólizas que no han hecho un reclamo y la clase 1 representa pólizas que sí han hecho un reclamo. Explicación métricas:\n",
    "\n",
    "1. Precision = Verdaderos Positivos (VP) / (Verdaderos Positivos (VP) + Falsos Positivos (FP))\n",
    "- Clase 0: 0.92 (92%): De todas las pólizas que el modelo predijo como sin reclamo (clase 0), el 92% realmente no hicieron un reclamo.\n",
    "- Clase 1: 0.28 (28%): De todas las pólizas que el modelo predijo como con reclamo (clase 1), solo el 28% realmente hicieron un reclamo.\n",
    "\n",
    "Interpretación: El modelo es bastante preciso para identificar pólizas sin reclamo (clase 0), pero es menos preciso para identificar aquellas con reclamo (clase 1).\n",
    "\n",
    "2. Recall = Verdaderos Positivos (VP) / (Verdaderos Positivos (VP) + Falsos Negativos (FP))\n",
    "- Clase 0: 1.00 (100%): El modelo identificó correctamente el 100% de todas las pólizas que realmente no hicieron un reclamo.\n",
    "- Clase 1: 0.01 (1%): El modelo identificó correctamente solo el 1% de todas las pólizas que realmente hicieron un reclamo.\n",
    "\n",
    "Interpretación: El modelo es excelente para detectar pólizas sin reclamo, pero casi no detecta las que realmente hacen un reclamo.\n",
    "\n",
    "3. F1-Score: media armónica entre la precisión y el recall\n",
    "\n",
    "4. Accuracy: el 92% de las predicciones totales del modelo fueron correctas.\n",
    "\n",
    "Interpretación: aunque el valor de exactitud parece alto, es importante recordar que esta métrica puede ser engañosa cuando hay un desbalance en las clases, como parece ser el caso aquí.\n",
    "\n",
    "5. ROC AUC Score: esta métrica mide la capacidad del modelo para distinguir entre las clases 0 y 1. Un valor de 0.5 indica que el modelo no tiene capacidad de discriminación (equivalente a lanzar una moneda), mientras que un valor de 1.0 indica una discriminación perfecta.\n",
    "\n",
    "Interpretación: Un ROC AUC de 0.726 indica que el modelo tiene una capacidad razonable para distinguir entre las clases, pero no excelente. A pesar de esto, el modelo parece estar favoreciendo en gran medida la clase 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95     74631\n",
      "           1       0.27      0.08      0.13      6659\n",
      "\n",
      "    accuracy                           0.91     81290\n",
      "   macro avg       0.60      0.53      0.54     81290\n",
      "weighted avg       0.87      0.91      0.88     81290\n",
      "\n",
      "ROC AUC Score: 0.7381735911118705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Random Forest\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretación: aunque este modelo es mejor que el anterior, todavía sigue presentando dificultades para detectar las pólizas que realmente hacen un reclamo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobremuestreo (Oversampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos la técnica SMOTE (Synthetic Minority Oversampling Technique) para generar ejemplos sintéticos de la clase minoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     74631\n",
      "           1       0.24      0.17      0.20      6659\n",
      "\n",
      "    accuracy                           0.89     81290\n",
      "   macro avg       0.58      0.56      0.57     81290\n",
      "weighted avg       0.87      0.89      0.88     81290\n",
      "\n",
      "ROC AUC Score: 0.7306324621266379\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sobremuestreo usando SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Entrenar el modelo con los datos sobremuestreados\n",
    "rf_model_smote = RandomForestClassifier(random_state=42)\n",
    "rf_model_smote.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predecir y evaluar\n",
    "y_pred_smote = rf_model_smote.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_smote))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, rf_model_smote.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submuestreo (Undersampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, podemos reducir la cantidad de ejemplos de la clase mayoritaria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.65      0.78     74631\n",
      "           1       0.16      0.75      0.26      6659\n",
      "\n",
      "    accuracy                           0.66     81290\n",
      "   macro avg       0.56      0.70      0.52     81290\n",
      "weighted avg       0.90      0.66      0.73     81290\n",
      "\n",
      "ROC AUC Score: 0.7640219131769996\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Submuestreo usando RandomUnderSampler\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Entrenar el modelo con los datos submuestreados\n",
    "rf_model_undersample = RandomForestClassifier(random_state=42)\n",
    "rf_model_undersample.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predecir y evaluar\n",
    "y_pred_undersample = rf_model_undersample.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_undersample))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, rf_model_undersample.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajuste del Umbral de Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, el modelo de Random Forest clasifica las instancias como positivas (1, pólizas con reclamo) si la probabilidad estimada es mayor que 0.5. Sin embargo, como tus clases están desbalanceadas, podrías cambiar este umbral para favorecer la detección de las pólizas que harán un reclamo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     74631\n",
      "           1       0.23      0.22      0.22      6659\n",
      "\n",
      "    accuracy                           0.88     81290\n",
      "   macro avg       0.58      0.58      0.58     81290\n",
      "weighted avg       0.87      0.88      0.87     81290\n",
      "\n",
      "ROC AUC Score: 0.7381735911118705\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener las probabilidades predichas\n",
    "y_prob = rf_model.predict_proba(X_test)[:, 1]  # Probabilidades para la clase 1\n",
    "\n",
    "# Ajustar el umbral (por ejemplo, 0.3)\n",
    "threshold = 0.3\n",
    "y_pred_adjusted = (y_prob >= threshold).astype(int)\n",
    "\n",
    "# Evaluar el nuevo modelo con el umbral ajustado\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinación de submuestreo y ajuste de umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.48      0.65     74631\n",
      "           1       0.13      0.90      0.23      6659\n",
      "\n",
      "    accuracy                           0.52     81290\n",
      "   macro avg       0.56      0.69      0.44     81290\n",
      "weighted avg       0.91      0.52      0.61     81290\n",
      "\n",
      "ROC AUC Score: 0.7640219131769996\n"
     ]
    }
   ],
   "source": [
    "# Aplicar submuestreo (undersampling) a los datos de entrenamiento\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Entrenar el modelo Random Forest con los datos submuestreados\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Obtener las probabilidades predichas para el conjunto de prueba\n",
    "y_prob = rf_model.predict_proba(X_test)[:, 1]  # Probabilidades para la clase 1 (reclamos)\n",
    "\n",
    "# Ajustar el umbral (por ejemplo, 0.3)\n",
    "threshold = 0.3\n",
    "y_pred_adjusted = (y_prob >= threshold).astype(int)\n",
    "\n",
    "# Evaluar el modelo con el umbral ajustado\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión:\n",
    "\n",
    "Mi mejor algoritmo es Random Forest con Undersampling (ROC AUC Score: 0.7640).\n",
    "En este caso, solo el 16% de las pólizas predichas como con reclamo fueron correctas. Por otro lado, el modelo identificó correctamente el 75% de las pólizas que hicieron un reclamo.\n",
    "Es decir, identifica pólizas que hicieron reclamos exageradamente, pero esto hace que la precisión de captarlas sea mucho más alta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción en el Conjunto de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.65      0.78    111950\n",
      "           1       0.16      0.75      0.26      9985\n",
      "\n",
      "    accuracy                           0.66    121935\n",
      "   macro avg       0.56      0.70      0.52    121935\n",
      "weighted avg       0.90      0.66      0.73    121935\n",
      "\n",
      "ROC AUC Score: 0.7643659043724138\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Cargar datos\n",
    "insurance_data = pd.read_csv('insurance_data.csv')\n",
    "vehicle_info = pd.read_csv('vehicle_info.csv')\n",
    "\n",
    "# Fusionar datasets\n",
    "merged_data = pd.merge(insurance_data, vehicle_info, on='VEHICLE_ID')\n",
    "\n",
    "# Seleccionar características y objetivo\n",
    "features = ['CUSTOMER_SENIORITY', 'SEX', 'INSR_TYPE', 'INSURED_VALUE', 'PREMIUM', 'PROD_YEAR', 'SEATS_NUM', 'CARRYING_CAPACITY', 'CCM_TON']\n",
    "categorical_features = ['SEX', 'INSR_TYPE']\n",
    "X = merged_data[features]\n",
    "y = merged_data['CLAIM_PAID'].notnull().astype(int)  # 1 si hay reclamo, 0 si no\n",
    "\n",
    "# Dividir datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Configurar ColumnTransformer para preprocesar datos\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), ['CUSTOMER_SENIORITY', 'INSURED_VALUE', 'PREMIUM', 'PROD_YEAR', 'SEATS_NUM', 'CARRYING_CAPACITY', 'CCM_TON']),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Crear pipeline de preprocesamiento y clasificación\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Submuestreo usando RandomUnderSampler\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Ajustar el modelo usando los datos submuestreados\n",
    "pipeline.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Realizar predicciones con el conjunto de prueba\n",
    "test_predictions = pipeline.predict(X_test)  # Usar pipeline directamente para hacer predicciones\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(classification_report(y_test, test_predictions))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "# Si necesitas guardar las predicciones\n",
    "test_data = pd.DataFrame(X_test)  # Asegúrate de incluir las características que necesitas\n",
    "test_data['PREDICTED_CLAIM'] = test_predictions\n",
    "test_data.to_csv('test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
